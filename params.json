{
  "name": "Prediction of Student Alcohol Consumption Level Using Various Machine Learning Techniques",
  "tagline": "",
  "body": "## ABSTRACT\r\nThis project compares the prediction accuracies of different machine learning algorithms, for alcohol consumption level among school students. In this pursuit, three machine learning models, such as _Decision Tree, Support Vector Machine and Naïve-Bayes classifier_ are used on two real life data sets. Additionally, the importance of various features are deduced, that highly impact the prediction accuracy of an algorithm.\r\n\r\n## PROBLEM DESCRIPTION\r\n![flow_diagram](https://cloud.githubusercontent.com/assets/20998518/21067018/2184f420-be26-11e6-9546-a97d23f30e8a.png)\r\n\r\nRegular consumption of alcohol has adverse impacts on our physical and mental health. There are many factors that influence the drinking pattern of a person, for example, gender, upbringing, socio-economic state of the country etc. Hence, it is worthwhile to study such influencing factors, with a view to limiting the alcohol consumption of a society, at large. The challenges of this study are two-fold: (a) real life data-set containing several features that gives rise to a specific alcohol consumption level and (b) accurate mining of such data-set so as to correctly isolate the important factors that maximize the consumption. Few researchers in the past did surveys to collect the data sets, concerning the drinking pattern among teenagers. Hence, this project addresses the second challenge. This project considers two real life data sets, from the UCI Machine Learning Repository, and applies three machine learning algorithms (e.g., _Decision Tree, Support Vector Machine and Naïve-Bayes Classifier_) to predict the alcohol consumption, subjected to various factors. The prediction accuracies are computed in terms of the average accuracy from 10-fold cross validation. Further, the features that strongly influence the alcohol consumption are extracted using _Information Gain_ analysis from a Decision Tree model.\r\n\r\n## DATASET\r\n![dataset](https://cloud.githubusercontent.com/assets/20998518/21066843/073836fa-be25-11e6-8773-b5474ab52a9e.png)\r\n\r\nThe original data was integrated into two data-sets related to Mathematics (with 395 examples) and the Portuguese language (649 records) classes. Contributors: Paulo Cortez and Alice Silva.\r\n\r\n## METHODOLOGY\r\n### Data Pre-processing\r\n* **Finding a Binary Output**: The dataset has two features, viz., _Dalc_ (workday alcohol consumption) and _Walc_ (weekend alcohol consumption), both in the range of 1 (very low) to 5 (very high). Derived output: Alc = (Walc X 2 + Dalc X 5) / 7, again, in the range of 1 – 5. Derived binary output: _**Alc_bin = Alc < Th ? 0 : 1**_ (where 0 and 1 denote non-alcoholic and alcoholic, respectively). _**Different values of Th are explored (e.g., 2, 2.5 and 3).**_\r\n\r\n* **Filtering poorly correlated features**: Using correlation co-efficient, 4 features were discarded for which the correlation values are less than a given threshold.\r\n\r\n### Machine Learning Models\r\n* **Decision Tree (DT)**: ): _Information Gain_ based analysis is used for prediction and feature extraction. Random validation (RV) and 10 –fold Cross Validation (XV) techniques are used for determining prediction accuracy.\r\n\r\n* **Support Vector Machine (SVM)**: A multi-class SVM with C-support vector classification is considered. The default parameters for the libSVM tool are used. Two kernel types (e.g., Radial Basis Function (RBF) and Sigmoid) are explored. Original categorical features are converted into discrete features in a sparse format.\u000B\r\n\r\n* **Naïve-Bayes Classifier (NBC)**: Gaussian and Multinomial decision rules are explored. The results from Bernoulli decision rule are discarded due to extremely poor accuracy. Laplace smoothing parameter is used for the multinomial decision rule. Original categorical features are converted into discrete features in a non-sparse format.\r\n\r\n \r\n\r\n\r\n![pred_dt_mat](https://cloud.githubusercontent.com/assets/20998518/21065745/2a5003d0-be1f-11e6-8ed2-c283b78c3e06.png)\r\n![pred_dt_por](https://cloud.githubusercontent.com/assets/20998518/21065744/2a4c1ba8-be1f-11e6-8e6a-e69fa76e7f4d.png)\r\n\r\n![rank](https://cloud.githubusercontent.com/assets/20998518/21067142/a1435f3a-be26-11e6-8f46-1869795898c7.png)\r\n\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}